import pandas as pd
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import LatentDirichletAllocation
import seaborn as sns
from wordcloud import WordCloud

# ðŸ”¹ Wczytanie przetworzonych danych
df = pd.read_csv("coffee_reviews_sentiment.csv", encoding="utf-8")

# ðŸ”¹ Model TF-IDF (przetwarzanie tekstu)
vectorizer = TfidfVectorizer(stop_words="english", max_features=1000)  # Maksymalnie 1000 sÅ‚Ã³w kluczowych
tfidf_matrix = vectorizer.fit_transform(df["desc_1"].astype(str))

# ðŸ”¹ Model LDA (wykrywanie tematÃ³w)
lda = LatentDirichletAllocation(n_components=5, random_state=42)  # 5 tematÃ³w
lda.fit(tfidf_matrix)

# ðŸ”¹ Pobranie sÅ‚Ã³w kluczowych dla kaÅ¼dego tematu
terms = vectorizer.get_feature_names_out()
topics = {}

for topic_idx, topic in enumerate(lda.components_):
    top_words = [terms[i] for i in topic.argsort()[:-11:-1]]  # TOP 10 sÅ‚Ã³w dla kaÅ¼dego tematu
    topics[f"Temat {topic_idx+1}"] = top_words

# ðŸ”¹ WyÅ›wietlenie tematÃ³w
print("\nðŸ“Œ Kluczowe tematy w recenzjach:")
for temat, slowa in topics.items():
    print(f"{temat}: {', '.join(slowa)}")

# ðŸ”¹ Zapisanie tematÃ³w do pliku
with open("coffee_topics.txt", "w", encoding="utf-8") as f:
    for temat, slowa in topics.items():
        f.write(f"{temat}: {', '.join(slowa)}\n")

print("\nâœ… Analiza tematÃ³w zakoÅ„czona! Wyniki zapisane w coffee_topics.txt.")



# ðŸ”¹ PoÅ‚Ä…czenie wszystkich sÅ‚Ã³w kluczowych w jeden tekst
all_words = " ".join(sum(topics.values(), []))

# ðŸ”¹ Tworzenie chmury sÅ‚Ã³w
wordcloud = WordCloud(width=800, height=400, background_color="white", colormap="coolwarm").generate(all_words)

# ðŸ”¹ Rysowanie chmury sÅ‚Ã³w
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")  # UsuniÄ™cie osi dla lepszej czytelnoÅ›ci
plt.title("â˜• Chmura sÅ‚Ã³w z recenzji kawy", fontsize=16)

plt.show()
